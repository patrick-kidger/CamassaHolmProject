{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the values of a single peakon on a coarse grid, this DNN finds the\n",
    "# values of the peakon on a finer grid.\n",
    "# Essentially, given the values shown by the @ symbols, it will output its \n",
    "# predictions for the values of the . symbols (and the four @ symbols bounding\n",
    "# them).\n",
    "#\n",
    "#\n",
    "# @   @   @   @   @   @\n",
    "#\n",
    "#\n",
    "#\n",
    "# @   @   @   @   @   @\n",
    "#\n",
    "#\n",
    "#\n",
    "# @   @   @...@   @   @\n",
    "#         .....\n",
    "#         .....\n",
    "#         .....\n",
    "# @   @   @...@   @   @\n",
    "#\n",
    "#\n",
    "#\n",
    "# @   @   @   @   @   @\n",
    "#\n",
    "#\n",
    "#\n",
    "# @   @   @   @   @   @"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run project_base.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to False to use existing weights for the neural network.\n",
    "# Set to True to continue training the weights from where we left off last time.\n",
    "TRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_one_data():\n",
    "    \"\"\"Generates a random feature/label combination.\n",
    "    \n",
    "    Here the feature is the solution on a coarse grid and the label is the\n",
    "    solution on a fine grid.\"\"\"\n",
    "    \n",
    "    # Random solution to the CH equation\n",
    "    c = np.random.uniform(0, 10)\n",
    "    peakon = Peakon(c=c)\n",
    "    # Random location\n",
    "    t = np.random.uniform(0, 40)\n",
    "    x = c * t + np.random.uniform(-5, 5)\n",
    "    \n",
    "    # Grids at the location\n",
    "    cg = coarse_grid((t, x))\n",
    "    fg = fine_grid((t, x))\n",
    "    # Features: the solution on the coarse grid\n",
    "    X = peakon.on_grid(cg)\n",
    "    # Labels: the solution on the fine grid\n",
    "    y = peakon.on_grid(fg)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "class BilinearInterp(BilinearInterpBase):\n",
    "    @classmethod\n",
    "    def _predict(cls, Xi):\n",
    "        returnval = []\n",
    "        # Translation doesn't matter at this point so WLOG the fine grid is\n",
    "        # around 0, 0. (cls._interp makes the same assumption; these assumptions\n",
    "        # must be consistent)\n",
    "        for point in fine_grid((0, 0)):\n",
    "            returnval.append(cls._interp(Xi, point))\n",
    "        return returnval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './saved_models/first_reg/'\n",
    "\n",
    "# DNN hyperparameters\n",
    "hidden_units = [1000] * 20\n",
    "logits = 121  # = (_fine_grid_fineness.t + 1) * (_fine_grid_fineness.x + 1)\n",
    "              # i.e. the number of fine grid points.\n",
    "drop_rate = 0.4\n",
    "batch_size = 100\n",
    "batch_reuse = 1  # See BatchData for an explanation of batch reuse.\n",
    "steps = 20000\n",
    "log_steps = 1000  # How many steps to print the current loss.\n",
    "\n",
    "for layer in hidden_units:\n",
    "    model_dir += '{}_'.format(layer)\n",
    "model_dir += '{}_'.format(logits)\n",
    "\n",
    "model_dir += 'D0{}_'.format(int(drop_rate * 10))\n",
    "model_dir += 'BS{}_'.format(batch_size)\n",
    "model_dir += 'BR{}'.format(batch_reuse)\n",
    "\n",
    "k_init = tfi.truncated_normal(mean=0, stddev=0.06)\n",
    "model = Sequential()\n",
    "for units in hidden_units:\n",
    "    model.add(tfla.Dense(units=units,\n",
    "                         activation=tf.nn.relu,\n",
    "                         kernel_initializer=k_init))\n",
    "    model.add_train(tfla.Dropout(rate=drop_rate))\n",
    "model.add(tfla.Dense(units=logits))\n",
    "model.set_kwargs(model_dir=model_dir,\n",
    "                 config=tfe.RunConfig(log_step_count_steps=log_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './saved_models/first_reg/1000_1000_1000_1000_1000_1000_1000_1000_1000_1000_1000_1000_1000_1000_1000_1000_1000_1000_1000_1000_121_D04_BS100_BR1', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fecfc816898>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "dnn = model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    train_input_fn = BatchData(gen_one_data, batch_size, batch_reuse)\n",
    "    dnn.train(input_fn=train_input_fn, max_steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = gen_test_data(gen_one_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./saved_models/first_reg/1000_1000_1000_1000_1000_1000_1000_1000_1000_1000_1000_1000_1000_1000_1000_1000_1000_1000_1000_1000_121_D04_BS100_BR1/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prediction': array([[0.14926415, 0.15409765, 0.16087928, 0.15257994, 0.15464315,\n",
       "         0.15393828, 0.141984  , 0.16744604, 0.15511741, 0.13943319,\n",
       "         0.16450201, 0.15790605, 0.15299832, 0.13827906, 0.18118531,\n",
       "         0.16429103, 0.17651638, 0.15372189, 0.15470735, 0.17310521,\n",
       "         0.17528853, 0.1794029 , 0.16731911, 0.16218502, 0.14034962,\n",
       "         0.1649023 , 0.14658231, 0.17577329, 0.15583617, 0.15748532,\n",
       "         0.17350795, 0.17501876, 0.15382826, 0.15524626, 0.16050107,\n",
       "         0.13932014, 0.16038425, 0.15267   , 0.16207435, 0.17448118,\n",
       "         0.15856459, 0.15161744, 0.14700493, 0.18476644, 0.16917386,\n",
       "         0.14209846, 0.18142125, 0.14702185, 0.13393832, 0.13556312,\n",
       "         0.14077205, 0.1709107 , 0.15446562, 0.14837456, 0.17186993,\n",
       "         0.13683722, 0.14588793, 0.15285126, 0.16634555, 0.16339104,\n",
       "         0.14849687, 0.17550542, 0.15128431, 0.19399827, 0.16663549,\n",
       "         0.15932268, 0.1436305 , 0.15918793, 0.15121963, 0.16070648,\n",
       "         0.14088   , 0.15938124, 0.12918587, 0.16826461, 0.16412081,\n",
       "         0.14562767, 0.14141355, 0.15166914, 0.15066992, 0.14087658,\n",
       "         0.16433837, 0.13800212, 0.17347745, 0.14696407, 0.13130387,\n",
       "         0.14751576, 0.11449804, 0.14528343, 0.1558219 , 0.14137249,\n",
       "         0.1694272 , 0.14313547, 0.14695083, 0.15049367, 0.14827718,\n",
       "         0.13380171, 0.1521294 , 0.13937264, 0.15355426, 0.16047226,\n",
       "         0.14805399, 0.18302133, 0.16525225, 0.1869348 , 0.1383826 ,\n",
       "         0.14771472, 0.13994055, 0.14730383, 0.13740176, 0.12295402,\n",
       "         0.14244127, 0.13089389, 0.13502063, 0.16769024, 0.16903631,\n",
       "         0.16088184, 0.13321167, 0.17747366, 0.15854254, 0.15926123,\n",
       "         0.13441798]]),\n",
       " 'actual': array([[1.12793653, 1.13927248, 1.15072236, 1.16228731, 1.1739685 ,\n",
       "         1.18576708, 1.19768423, 1.20972116, 1.22187906, 1.23415915,\n",
       "         1.24656265, 1.10158167, 1.11265275, 1.12383509, 1.13512982,\n",
       "         1.14653807, 1.15806097, 1.16969967, 1.18145535, 1.19332918,\n",
       "         1.20532233, 1.21743602, 1.0758426 , 1.086655  , 1.09757606,\n",
       "         1.10860689, 1.11974857, 1.13100223, 1.14236899, 1.15384999,\n",
       "         1.16544638, 1.17715931, 1.18898995, 1.05070494, 1.0612647 ,\n",
       "         1.07193059, 1.08270367, 1.09358502, 1.10457573, 1.11567691,\n",
       "         1.12688964, 1.13821507, 1.14965433, 1.16120854, 1.02615464,\n",
       "         1.03646766, 1.04688433, 1.0574057 , 1.0680328 , 1.07876671,\n",
       "         1.08960849, 1.10055924, 1.11162005, 1.12279201, 1.13407626,\n",
       "         1.00217796, 1.01225002, 1.0224233 , 1.03269882, 1.04307762,\n",
       "         1.05356072, 1.06414919, 1.07484406, 1.08564643, 1.09655735,\n",
       "         1.10757794, 0.97876152, 0.98859823, 0.99853381, 1.00856924,\n",
       "         1.01870553, 1.02894369, 1.03928475, 1.04972973, 1.06027969,\n",
       "         1.07093568, 1.08169876, 0.95589221, 0.96549909, 0.97520251,\n",
       "         0.98500346, 0.99490291, 1.00490185, 1.01500128, 1.02520222,\n",
       "         1.03550567, 1.04591267, 1.05642427, 0.93355726, 0.94293966,\n",
       "         0.95241636, 0.96198831, 0.97165645, 0.98142176, 0.99128521,\n",
       "         1.0012478 , 1.0113105 , 1.02147434, 1.03174033, 0.91174417,\n",
       "         0.92090735, 0.93016263, 0.93951092, 0.94895316, 0.9584903 ,\n",
       "         0.96812328, 0.97785308, 0.98768067, 0.99760703, 1.00763314,\n",
       "         0.89044076, 0.89938984, 0.90842886, 0.91755872, 0.92678034,\n",
       "         0.93609464, 0.94550254, 0.955005  , 0.96460296, 0.97429738,\n",
       "         0.98408924]]),\n",
       " 'average_loss': 0.8210704459104087,\n",
       " 'loss': 99.34952395515946}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_regressor(testing_data, dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': array([[1.12793653, 1.12912279, 1.13030906, 1.13149532, 1.13268158,\n",
       "         1.13386784, 1.1350541 , 1.13624036, 1.13742662, 1.13861288,\n",
       "         1.24656265, 1.12556157, 1.12674534, 1.1279291 , 1.12911287,\n",
       "         1.13029663, 1.13148039, 1.13266416, 1.13384792, 1.13503168,\n",
       "         1.13621545, 1.24393792, 1.12318662, 1.12436788, 1.12554915,\n",
       "         1.12673041, 1.12791168, 1.12909295, 1.13027421, 1.13145548,\n",
       "         1.13263674, 1.13381801, 1.24131318, 1.12081166, 1.12199043,\n",
       "         1.1231692 , 1.12434796, 1.12552673, 1.1267055 , 1.12788427,\n",
       "         1.12906303, 1.1302418 , 1.13142057, 1.23868845, 1.1184367 ,\n",
       "         1.11961297, 1.12078924, 1.12196551, 1.12314178, 1.12431805,\n",
       "         1.12549432, 1.12667059, 1.12784686, 1.12902313, 1.23606372,\n",
       "         1.11606174, 1.11723552, 1.11840929, 1.11958306, 1.12075683,\n",
       "         1.12193061, 1.12310438, 1.12427815, 1.12545192, 1.1266257 ,\n",
       "         1.23343898, 1.11368679, 1.11485806, 1.11602934, 1.11720061,\n",
       "         1.11837188, 1.11954316, 1.12071443, 1.12188571, 1.12305698,\n",
       "         1.12422826, 1.23081425, 1.11131183, 1.11248061, 1.11364938,\n",
       "         1.11481816, 1.11598694, 1.11715571, 1.11832449, 1.11949327,\n",
       "         1.12066204, 1.12183082, 1.22818951, 1.10893687, 1.11010315,\n",
       "         1.11126943, 1.11243571, 1.11360199, 1.11476827, 1.11593455,\n",
       "         1.11710082, 1.1182671 , 1.11943338, 1.22556478, 1.10656191,\n",
       "         1.10772569, 1.10888948, 1.11005326, 1.11121704, 1.11238082,\n",
       "         1.1135446 , 1.11470838, 1.11587216, 1.11703595, 1.22294005,\n",
       "         0.89044076, 0.89137725, 0.89231373, 0.89325022, 0.8941867 ,\n",
       "         0.89512319, 0.89605967, 0.89699616, 0.89793264, 0.89886913,\n",
       "         0.98408924]]),\n",
       " 'actual': array([[1.12793653, 1.13927248, 1.15072236, 1.16228731, 1.1739685 ,\n",
       "         1.18576708, 1.19768423, 1.20972116, 1.22187906, 1.23415915,\n",
       "         1.24656265, 1.10158167, 1.11265275, 1.12383509, 1.13512982,\n",
       "         1.14653807, 1.15806097, 1.16969967, 1.18145535, 1.19332918,\n",
       "         1.20532233, 1.21743602, 1.0758426 , 1.086655  , 1.09757606,\n",
       "         1.10860689, 1.11974857, 1.13100223, 1.14236899, 1.15384999,\n",
       "         1.16544638, 1.17715931, 1.18898995, 1.05070494, 1.0612647 ,\n",
       "         1.07193059, 1.08270367, 1.09358502, 1.10457573, 1.11567691,\n",
       "         1.12688964, 1.13821507, 1.14965433, 1.16120854, 1.02615464,\n",
       "         1.03646766, 1.04688433, 1.0574057 , 1.0680328 , 1.07876671,\n",
       "         1.08960849, 1.10055924, 1.11162005, 1.12279201, 1.13407626,\n",
       "         1.00217796, 1.01225002, 1.0224233 , 1.03269882, 1.04307762,\n",
       "         1.05356072, 1.06414919, 1.07484406, 1.08564643, 1.09655735,\n",
       "         1.10757794, 0.97876152, 0.98859823, 0.99853381, 1.00856924,\n",
       "         1.01870553, 1.02894369, 1.03928475, 1.04972973, 1.06027969,\n",
       "         1.07093568, 1.08169876, 0.95589221, 0.96549909, 0.97520251,\n",
       "         0.98500346, 0.99490291, 1.00490185, 1.01500128, 1.02520222,\n",
       "         1.03550567, 1.04591267, 1.05642427, 0.93355726, 0.94293966,\n",
       "         0.95241636, 0.96198831, 0.97165645, 0.98142176, 0.99128521,\n",
       "         1.0012478 , 1.0113105 , 1.02147434, 1.03174033, 0.91174417,\n",
       "         0.92090735, 0.93016263, 0.93951092, 0.94895316, 0.9584903 ,\n",
       "         0.96812328, 0.97785308, 0.98768067, 0.99760703, 1.00763314,\n",
       "         0.89044076, 0.89938984, 0.90842886, 0.91755872, 0.92678034,\n",
       "         0.93609464, 0.94550254, 0.955005  , 0.96460296, 0.97429738,\n",
       "         0.98408924]]),\n",
       " 'average_loss': 0.008585851451989791,\n",
       " 'loss': 1.0388880256907647}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_regressor(testing_data, BilinearInterp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
