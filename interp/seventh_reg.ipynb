{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As first_reg, but with features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run project_base.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to False to use existing weights for the neural network.\n",
    "# Set to True to continue training the weights from where we left off last time.\n",
    "TRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BilinearInterp(FineGridPredictorMixin, BilinearInterpBase):\n",
    "    pass\n",
    "    \n",
    "    \n",
    "class NearestInterp(FineGridPredictorMixin, NearestInterpBase):\n",
    "    pass\n",
    "\n",
    "\n",
    "class PolyInterp(FineGridPredictorMixin, PolyInterpBase):\n",
    "    pass\n",
    "    \n",
    "    \n",
    "class ScaleData(Processor):\n",
    "    \"\"\"Scales data to between -1 and 1.\"\"\"\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.X_mean = None\n",
    "        self.X_extent = None\n",
    "        super(ScaleData, self).__init__(*args, **kwargs)\n",
    "        \n",
    "    def transform(self, X, y):\n",
    "        X_scaled, y_scaled, X_mean, X_extent = self._transform(X, y)\n",
    "        self.X_mean = X_mean\n",
    "        self.X_extent = X_extent\n",
    "        \n",
    "        return X_scaled, y_scaled\n",
    "    \n",
    "    @staticmethod\n",
    "    def _transform(X, y):\n",
    "        X_mean = np.mean(X)\n",
    "        X_from_mean = X - X_mean\n",
    "        X_extent = np.max(np.abs(X_from_mean))\n",
    "        X_scaled = X_from_mean / X_extent\n",
    "        y_scaled = (y - X_mean) / X_extent\n",
    "        return X_scaled, y_scaled, X_mean, X_extent\n",
    "    \n",
    "    @classmethod\n",
    "    def once(cls, X, y):\n",
    "        \"\"\"One-off call to perform a transform without the overheard\n",
    "        of creating the class.\n",
    "        \"\"\"\n",
    "        X_scaled, y_scaled, X_mean, X_extent = cls._transform(X, y)\n",
    "        return X_scaled, y_scaled\n",
    "    \n",
    "    def _inverse_transform(self, y):\n",
    "        return (y * self.X_extent) + self.X_mean\n",
    "        \n",
    "    \n",
    "    \n",
    "def gen_one_data():\n",
    "    \"\"\"Generates a random feature/label combination.\n",
    "    \n",
    "    Here the feature is the solution on a coarse grid, and the\n",
    "    label is the solution on a fine grid, with both of them scaled.\n",
    "    \"\"\"\n",
    "    \n",
    "    X, y = gen_one_peakon()\n",
    "    return ScaleData.once(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './saved_models/seventh_reg/1000x10_121_D04', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd865702a20>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "### DNN hyperparameters\n",
    "hidden_units = [1000] * 10\n",
    "# i.e. the number of fine grid points.\n",
    "logits = (fine_grid_fineness.t + 1) * (fine_grid_fineness.x + 1)\n",
    "drop_rate = 0.4\n",
    "\n",
    "### Training hyperparameters #1\n",
    "gradient_clip = 5.0  # May be set to None to turn off gradient clipping\n",
    "\n",
    "### Logging/saving hyperparameters\n",
    "log_steps = 1000  # How many steps to print the current loss.\n",
    "model_dir = './saved_models/seventh_reg/'\n",
    "model_dir = model_dir_str(model_dir, hidden_units, logits, drop_rate)\n",
    "\n",
    "dnn = Sequential.create_dnn(hidden_units, logits, drop_rate=drop_rate,\n",
    "                            model_dir=model_dir, log_steps=log_steps,\n",
    "                            gradient_clip=gradient_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
     ]
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    ### Training hyperparameters #2\n",
    "    batch_size = 50\n",
    "    steps = 2000\n",
    "    train_input_fn = IdentityProcess().init(BatchData(gen_one_data, batch_size))\n",
    "    dnn.train(input_fn=train_input_fn(use_tf=True), max_steps=steps)\n",
    "    \n",
    "#     batch_size = 100\n",
    "#     steps = 20000\n",
    "#     train_input_fn = BatchData(gen_one_data, batch_size)\n",
    "#     dnn.train(input_fn=train_input_fn, max_steps=steps)\n",
    "    \n",
    "#     batch_size = 1000\n",
    "#     steps = 25000\n",
    "#     train_input_fn = BatchData(gen_one_data, batch_size)\n",
    "#     dnn.train(input_fn=train_input_fn, max_steps=steps)\n",
    "    \n",
    "#     batch_size = 5000\n",
    "#     steps = 35000\n",
    "#     train_input_fn = BatchData(gen_one_data, batch_size)\n",
    "#     dnn.train(input_fn=train_input_fn, max_steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = gen_one_peakon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edcd784f6f094af8b93bd093eaa90fd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./saved_models/seventh_reg/1000x10_121_D04/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "poly_deg = 5\n",
    "results = plot_regressors([(Perfect(), None, 'Exact'),\n",
    "                           (dnn, ScaleData(), 'DNN'),\n",
    "                           (BilinearInterp(), None, 'Bilinear'),\n",
    "                           (PolyInterp(poly_deg), None, 'Poly-{}'.format(poly_deg))],\n",
    "                          X,\n",
    "                          y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.13680501680071605, 2.68223820688442, 84.18740987394793)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].loss, result[1].loss, result[2].loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
