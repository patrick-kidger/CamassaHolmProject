{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As single_peakon, but trained on multipeakons!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run base/base_eq.ipynb\n",
    "%run base/base_plot.ipynb\n",
    "%run base/base_ml.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to False to use existing weights for the neural network.\n",
    "# Set to True to continue training the weights from where we left off last time.\n",
    "TRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_one_peakon_on_grid():\n",
    "    \"\"\"Returns a (feature, label) pair, where the features are the values of\n",
    "    a single-peakon solution on a coarse grid, and the labels are the values of\n",
    "    the single-peakon solution on a fine grid.\n",
    "    \"\"\"\n",
    "    point, peakon = gen_one_peakon()\n",
    "    return sol_on_grid(point, peakon)\n",
    "\n",
    "def gen_two_peakon_on_grid():\n",
    "    \"\"\"Returns a (feature, label) pair, where the features are the values of\n",
    "    a two-peakon solution on a coarse grid, and the labels are the values of\n",
    "    the two-peakon solution on a fine grid.\n",
    "    \"\"\"\n",
    "    point, twopeakon = gen_two_peakon()\n",
    "    return sol_on_grid(point, twopeakon)\n",
    "\n",
    "def gen_one_data():\n",
    "    return tools.random_function(gen_one_peakon_on_grid, gen_two_peakon_on_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4559ce3cc0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Processor checkpoint file found, restoring values.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu/model.ckpt-9000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 9000 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 9000 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu\n",
      "INFO:tensorflow:loss = 1.4531121, step = 9001\n",
      "INFO:tensorflow:global_step/sec: 7.02757\n",
      "INFO:tensorflow:loss = 1.1038193, step = 10001 (142.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.04317\n",
      "INFO:tensorflow:loss = 0.9146193, step = 11001 (141.982 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.08661\n",
      "INFO:tensorflow:loss = 0.8980792, step = 12001 (141.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.13233\n",
      "INFO:tensorflow:loss = 0.8574711, step = 13001 (140.206 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13243 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 13243 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu\n",
      "INFO:tensorflow:global_step/sec: 7.05504\n",
      "INFO:tensorflow:loss = 0.74866205, step = 14001 (141.743 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.79446\n",
      "INFO:tensorflow:loss = 237242.31, step = 15001 (147.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.72742\n",
      "INFO:tensorflow:loss = 250572.58, step = 16001 (148.645 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.84856\n",
      "INFO:tensorflow:loss = 266310.66, step = 17001 (146.016 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 17351 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 17351 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu\n",
      "INFO:tensorflow:global_step/sec: 6.73112\n",
      "INFO:tensorflow:loss = 271041.06, step = 18001 (148.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.52812\n",
      "INFO:tensorflow:loss = 266326.75, step = 19001 (153.184 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 20000 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu\n",
      "INFO:tensorflow:Loss for final step: 5772282400000.0.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 20000 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu\n",
      "INFO:tensorflow:loss = 20542440000000.0, step = 20001\n",
      "INFO:tensorflow:Saving checkpoints for 20884 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 20884 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu\n",
      "INFO:tensorflow:global_step/sec: 1.47583\n",
      "INFO:tensorflow:loss = 283999.78, step = 21001 (677.585 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 21795 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 21795 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu\n",
      "INFO:tensorflow:global_step/sec: 1.52121\n",
      "INFO:tensorflow:loss = 276173.66, step = 22001 (657.371 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22698 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 22698 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu\n",
      "INFO:tensorflow:global_step/sec: 1.4924\n",
      "INFO:tensorflow:loss = 257912.7, step = 23001 (670.063 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 23580 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 23580 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu\n",
      "INFO:tensorflow:global_step/sec: 1.45933\n",
      "INFO:tensorflow:loss = 232017.12, step = 24001 (685.248 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24474 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 24474 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu\n",
      "INFO:tensorflow:global_step/sec: 1.52287\n",
      "INFO:tensorflow:loss = 1357219500000000.0, step = 25001 (656.654 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25378 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 25378 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu\n",
      "INFO:tensorflow:global_step/sec: 1.48495\n",
      "INFO:tensorflow:loss = 294699.88, step = 26001 (673.425 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26274 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 26274 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu\n",
      "INFO:tensorflow:global_step/sec: 1.4891\n",
      "INFO:tensorflow:loss = 284999.25, step = 27001 (671.550 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 27161 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 27161 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu\n",
      "INFO:tensorflow:global_step/sec: 1.47847\n",
      "INFO:tensorflow:loss = 269310.94, step = 28001 (676.373 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28052 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 28053 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu\n",
      "INFO:tensorflow:Saving checkpoints for 28950 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 28951 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu\n",
      "INFO:tensorflow:global_step/sec: 1.49441\n",
      "INFO:tensorflow:loss = 256685.52, step = 29001 (669.159 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 29848 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 29849 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 30000 into ./saved_models/grid_multi_peakon/1200x15_121_D04_NormalisationOverall_selu\n",
      "INFO:tensorflow:Loss for final step: 273011.03.\n"
     ]
    }
   ],
   "source": [
    "### DNN hyperparameters\n",
    "hidden_units = [1200] * 15\n",
    "# i.e. the number of fine grid points.\n",
    "logits = (fine_grid_fineness.t + 1) * (fine_grid_fineness.x + 1)\n",
    "drop_rate = 0.4\n",
    "drop_type = 'dropout'\n",
    "preprocessor = NormalisationOverall(momentum=0.999)\n",
    "activation = tf.nn.selu\n",
    "uuid = None\n",
    "\n",
    "### Training hyperparameters #1\n",
    "gradient_clip = None  # May be set to None to turn off gradient clipping\n",
    "\n",
    "### Logging/saving hyperparameters\n",
    "log_steps = 1000  # How many steps to print the current loss.\n",
    "model_dir_base = './saved_models/grid_multi_peakon/'\n",
    "model_dir = model_dir_str(model_dir_base, hidden_units, logits, \n",
    "                          drop_rate=drop_rate, drop_type=drop_type,\n",
    "                          preprocessor=preprocessor, activation=activation, \n",
    "                          uuid=uuid)\n",
    "\n",
    "dnn = create_dnn(hidden_units, logits, drop_rate=drop_rate,\n",
    "                 drop_type=drop_type, model_dir=model_dir, \n",
    "                 log_steps=log_steps, activation=activation, \n",
    "                 gradient_clip=gradient_clip, batch_norm=False)\n",
    "preprocessor.load(model_dir)\n",
    "\n",
    "if TRAIN:\n",
    "    ### Training hyperparameters #2\n",
    "    batch_size = 30\n",
    "    steps = 20000\n",
    "    train_input_fn = preprocessor.data(BatchData(gen_one_data=gen_one_data, batch_size=batch_size))\n",
    "    dnn.train(input_fn=train_input_fn(use_tf=True), max_steps=steps, \n",
    "              hooks=[ProcessorSavingHook(preprocessor, model_dir)])\n",
    "\n",
    "    batch_size = 300\n",
    "    steps = 30000\n",
    "    train_input_fn = preprocessor.data(BatchData(gen_one_data=gen_one_data, batch_size=batch_size))\n",
    "    dnn.train(input_fn=train_input_fn(use_tf=True), max_steps=steps, \n",
    "              hooks=[ProcessorSavingHook(preprocessor, model_dir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f44fd9be1d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:No processor checkpoint file './saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu/processor-checkpoint' found.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 0 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu\n",
      "INFO:tensorflow:loss = 148.68126, step = 1\n",
      "INFO:tensorflow:global_step/sec: 7.42593\n",
      "INFO:tensorflow:loss = 7.2152056e-05, step = 1001 (134.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.39089\n",
      "INFO:tensorflow:loss = 3.5876652e-05, step = 2001 (135.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.29514\n",
      "INFO:tensorflow:loss = 0.0023155836, step = 3001 (137.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.22754\n",
      "INFO:tensorflow:loss = 0.0029786816, step = 4001 (138.359 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4390 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 4390 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu\n",
      "INFO:tensorflow:global_step/sec: 7.16837\n",
      "INFO:tensorflow:loss = 0.0001781138, step = 5001 (139.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.25631\n",
      "INFO:tensorflow:loss = 0.0029680848, step = 6001 (137.811 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.21756\n",
      "INFO:tensorflow:loss = 0.004096386, step = 7001 (138.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.18121\n",
      "INFO:tensorflow:loss = 0.0049334634, step = 8001 (139.252 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8715 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 8715 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu\n",
      "INFO:tensorflow:global_step/sec: 7.16521\n",
      "INFO:tensorflow:loss = 0.009062198, step = 9001 (139.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.2379\n",
      "INFO:tensorflow:loss = 1525.8947, step = 10001 (138.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.00389\n",
      "INFO:tensorflow:loss = 1520.6519, step = 11001 (142.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.01951\n",
      "INFO:tensorflow:loss = 1512.1073, step = 12001 (142.460 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12935 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 12936 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu\n",
      "INFO:tensorflow:global_step/sec: 6.79977\n",
      "INFO:tensorflow:loss = 1498.2897, step = 13001 (147.064 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.74987\n",
      "INFO:tensorflow:loss = 1476.218, step = 14001 (148.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.72817\n",
      "INFO:tensorflow:loss = 1441.6304, step = 15001 (148.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.72867\n",
      "INFO:tensorflow:loss = 1388.9968, step = 16001 (148.617 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16973 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 16975 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu\n",
      "INFO:tensorflow:global_step/sec: 6.71478\n",
      "INFO:tensorflow:loss = 1312.2317, step = 17001 (148.925 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.86368\n",
      "INFO:tensorflow:loss = 1206.4259, step = 18001 (145.695 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.15961\n",
      "INFO:tensorflow:loss = 1070.0242, step = 19001 (139.672 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 20000 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu\n",
      "INFO:tensorflow:Loss for final step: 906.483.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 20000 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu\n",
      "INFO:tensorflow:loss = 903.3292, step = 20001\n",
      "INFO:tensorflow:Saving checkpoints for 20938 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 20938 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu\n",
      "INFO:tensorflow:global_step/sec: 1.55071\n",
      "INFO:tensorflow:loss = 722.52057, step = 21001 (644.867 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 21868 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 21868 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu\n",
      "INFO:tensorflow:global_step/sec: 1.56051\n",
      "INFO:tensorflow:loss = 543.3998, step = 22001 (640.815 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22817 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 22817 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu\n",
      "INFO:tensorflow:global_step/sec: 1.58824\n",
      "INFO:tensorflow:loss = 388.945, step = 23001 (629.628 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 23779 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 23779 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu\n",
      "INFO:tensorflow:global_step/sec: 1.60236\n",
      "INFO:tensorflow:loss = 272.29388, step = 24001 (624.081 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24725 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 24725 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu\n",
      "INFO:tensorflow:global_step/sec: 1.56165\n",
      "INFO:tensorflow:loss = 190.65303, step = 25001 (640.346 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25665 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 25665 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu\n",
      "INFO:tensorflow:global_step/sec: 1.58138\n",
      "INFO:tensorflow:loss = 131.2262, step = 26001 (632.361 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26606 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 26606 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu\n",
      "INFO:tensorflow:global_step/sec: 1.55489\n",
      "INFO:tensorflow:loss = 81.33935, step = 27001 (643.132 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 27555 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 27555 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu\n",
      "INFO:tensorflow:global_step/sec: 1.59939\n",
      "INFO:tensorflow:loss = 39.18687, step = 28001 (625.236 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28513 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 28513 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu\n",
      "INFO:tensorflow:global_step/sec: 1.59387\n",
      "INFO:tensorflow:loss = 12.494742, step = 29001 (627.403 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 29470 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 29470 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 30000 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu\n",
      "INFO:tensorflow:Loss for final step: 2.7595344.\n"
     ]
    }
   ],
   "source": [
    "### DNN hyperparameters\n",
    "hidden_units = [1200] * 15\n",
    "# i.e. the number of fine grid points.\n",
    "logits = (fine_grid_fineness.t + 1) * (fine_grid_fineness.x + 1)\n",
    "drop_rate = 0.0\n",
    "drop_type = 'dropout'\n",
    "preprocessor = NormalisationOverall(momentum=0.999)\n",
    "activation = tf.nn.selu\n",
    "uuid = None\n",
    "\n",
    "### Training hyperparameters #1\n",
    "gradient_clip = None  # May be set to None to turn off gradient clipping\n",
    "\n",
    "### Logging/saving hyperparameters\n",
    "log_steps = 1000  # How many steps to print the current loss.\n",
    "model_dir_base = './saved_models/grid_multi_peakon/'\n",
    "model_dir = model_dir_str(model_dir_base, hidden_units, logits, \n",
    "                          drop_rate=drop_rate, drop_type=drop_type,\n",
    "                          preprocessor=preprocessor, activation=activation, \n",
    "                          uuid=uuid)\n",
    "\n",
    "dnn = create_dnn(hidden_units, logits, drop_rate=drop_rate,\n",
    "                 drop_type=drop_type, model_dir=model_dir, \n",
    "                 log_steps=log_steps, activation=activation, \n",
    "                 gradient_clip=gradient_clip, batch_norm=False)\n",
    "preprocessor.load(model_dir)\n",
    "\n",
    "if TRAIN:\n",
    "    ### Training hyperparameters #2\n",
    "    batch_size = 30\n",
    "    steps = 20000\n",
    "    train_input_fn = preprocessor.data(BatchData(gen_one_data=gen_one_data, batch_size=batch_size))\n",
    "    dnn.train(input_fn=train_input_fn(use_tf=True), max_steps=steps, \n",
    "              hooks=[ProcessorSavingHook(preprocessor, model_dir)])\n",
    "\n",
    "    batch_size = 300\n",
    "    steps = 30000\n",
    "    train_input_fn = preprocessor.data(BatchData(gen_one_data=gen_one_data, batch_size=batch_size))\n",
    "    dnn.train(input_fn=train_input_fn(use_tf=True), max_steps=steps, \n",
    "              hooks=[ProcessorSavingHook(preprocessor, model_dir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f44fd9f5ef0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:No processor checkpoint file './saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu/processor-checkpoint' found.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 0 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu\n",
      "INFO:tensorflow:loss = 101.98955, step = 1\n",
      "INFO:tensorflow:global_step/sec: 6.10301\n",
      "INFO:tensorflow:loss = 0.010673741, step = 1001 (163.855 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.08725\n",
      "INFO:tensorflow:loss = 0.008342615, step = 2001 (164.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.11987\n",
      "INFO:tensorflow:loss = 0.009366613, step = 3001 (163.402 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3667 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 3667 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu\n",
      "INFO:tensorflow:global_step/sec: 6.24167\n",
      "INFO:tensorflow:loss = 0.009544406, step = 4001 (160.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.5041\n",
      "INFO:tensorflow:loss = 0.008650623, step = 5001 (153.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.46418\n",
      "INFO:tensorflow:loss = 0.008723321, step = 6001 (154.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.48812\n",
      "INFO:tensorflow:loss = 0.014402332, step = 7001 (154.128 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7556 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 7556 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu\n",
      "INFO:tensorflow:global_step/sec: 6.44712\n",
      "INFO:tensorflow:loss = 0.008139476, step = 8001 (155.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.28929\n",
      "INFO:tensorflow:loss = 0.0103752185, step = 9001 (159.000 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.3568\n",
      "INFO:tensorflow:loss = 0.025588732, step = 10001 (157.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.42636\n",
      "INFO:tensorflow:loss = 0.011004203, step = 11001 (155.609 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11376 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 11377 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu\n",
      "INFO:tensorflow:global_step/sec: 6.28627\n",
      "INFO:tensorflow:loss = 0.019313533, step = 12001 (159.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.23807\n",
      "INFO:tensorflow:loss = 0.00968599, step = 13001 (160.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.28353\n",
      "INFO:tensorflow:loss = 0.01999225, step = 14001 (159.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.46306\n",
      "INFO:tensorflow:loss = 0.018950803, step = 15001 (154.725 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15164 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 15165 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu\n",
      "INFO:tensorflow:global_step/sec: 6.34353\n",
      "INFO:tensorflow:loss = 0.018354628, step = 16001 (157.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.20484\n",
      "INFO:tensorflow:loss = 0.042452168, step = 17001 (161.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.15099\n",
      "INFO:tensorflow:loss = 0.015516278, step = 18001 (162.576 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18906 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 18906 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu\n",
      "INFO:tensorflow:global_step/sec: 6.22825\n",
      "INFO:tensorflow:loss = 0.03558906, step = 19001 (160.559 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 20000 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu\n",
      "INFO:tensorflow:Loss for final step: 0.059740398.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 20000 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu\n",
      "INFO:tensorflow:loss = 0.046274666, step = 20001\n",
      "INFO:tensorflow:Saving checkpoints for 20874 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 20874 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu\n",
      "INFO:tensorflow:global_step/sec: 1.46043\n",
      "INFO:tensorflow:loss = 0.04045767, step = 21001 (684.734 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 21763 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 21763 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu\n",
      "INFO:tensorflow:global_step/sec: 1.47244\n",
      "INFO:tensorflow:loss = 0.040014427, step = 22001 (679.144 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22633 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 22633 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu\n",
      "INFO:tensorflow:global_step/sec: 1.45114\n",
      "INFO:tensorflow:loss = 0.04016995, step = 23001 (689.114 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 23515 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 23515 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu\n",
      "INFO:tensorflow:global_step/sec: 1.49157\n",
      "INFO:tensorflow:loss = 0.04007749, step = 24001 (670.433 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24410 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 24410 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu\n",
      "INFO:tensorflow:global_step/sec: 1.46464\n",
      "INFO:tensorflow:loss = 0.039971758, step = 25001 (682.762 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25293 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 25293 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu\n",
      "INFO:tensorflow:global_step/sec: 1.5009\n",
      "INFO:tensorflow:loss = 0.0400156, step = 26001 (666.264 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26193 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 26193 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu\n",
      "INFO:tensorflow:global_step/sec: 1.48499\n",
      "INFO:tensorflow:loss = 0.040012114, step = 27001 (673.406 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 27082 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 27082 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu\n",
      "INFO:tensorflow:Saving checkpoints for 27954 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 27954 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu\n",
      "INFO:tensorflow:global_step/sec: 1.45215\n",
      "INFO:tensorflow:loss = 0.039945636, step = 28001 (688.633 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 28834 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 28834 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu\n",
      "INFO:tensorflow:global_step/sec: 1.46375\n",
      "INFO:tensorflow:loss = 0.039998107, step = 29001 (683.176 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 29716 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 29716 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 30000 into ./saved_models/grid_multi_peakon/1200x15_121_D04_ScaleDataOverall_relu\n",
      "INFO:tensorflow:Loss for final step: 0.040032133.\n"
     ]
    }
   ],
   "source": [
    "### DNN hyperparameters\n",
    "hidden_units = [1200] * 15\n",
    "# i.e. the number of fine grid points.\n",
    "logits = (fine_grid_fineness.t + 1) * (fine_grid_fineness.x + 1)\n",
    "drop_rate = 0.4\n",
    "drop_type = 'dropout'\n",
    "preprocessor = ScaleDataOverall(momentum=0.999)\n",
    "activation = tf.nn.relu\n",
    "uuid = None\n",
    "\n",
    "### Training hyperparameters #1\n",
    "gradient_clip = 5.0  # May be set to None to turn off gradient clipping\n",
    "\n",
    "### Logging/saving hyperparameters\n",
    "log_steps = 1000  # How many steps to print the current loss.\n",
    "model_dir_base = './saved_models/grid_multi_peakon/'\n",
    "model_dir = model_dir_str(model_dir_base, hidden_units, logits, \n",
    "                          drop_rate=drop_rate, drop_type=drop_type,\n",
    "                          preprocessor=preprocessor, activation=activation, \n",
    "                          uuid=uuid)\n",
    "\n",
    "dnn = create_dnn(hidden_units, logits, drop_rate=drop_rate,\n",
    "                 drop_type=drop_type, model_dir=model_dir, \n",
    "                 log_steps=log_steps, activation=activation, \n",
    "                 gradient_clip=gradient_clip, batch_norm=False)\n",
    "preprocessor.load(model_dir)\n",
    "\n",
    "if TRAIN:\n",
    "    ### Training hyperparameters #2\n",
    "    batch_size = 30\n",
    "    steps = 20000\n",
    "    train_input_fn = preprocessor.data(BatchData(gen_one_data=gen_one_data, batch_size=batch_size))\n",
    "    dnn.train(input_fn=train_input_fn(use_tf=True), max_steps=steps, \n",
    "              hooks=[ProcessorSavingHook(preprocessor, model_dir)])\n",
    "\n",
    "    batch_size = 300\n",
    "    steps = 30000\n",
    "    train_input_fn = preprocessor.data(BatchData(gen_one_data=gen_one_data, batch_size=batch_size))\n",
    "    dnn.train(input_fn=train_input_fn(use_tf=True), max_steps=steps, \n",
    "              hooks=[ProcessorSavingHook(preprocessor, model_dir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './saved_models/grid_multi_peakon/1200x15_121_D00_ScaleDataOverall_relu', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f44fc66c400>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Processor checkpoint file found, restoring values.\n",
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./saved_models/grid_multi_peakon/1200x15_121_D00_ScaleDataOverall_relu/model.ckpt-22864\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 22864 into ./saved_models/grid_multi_peakon/1200x15_121_D00_ScaleDataOverall_relu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 22864 into ./saved_models/grid_multi_peakon/1200x15_121_D00_ScaleDataOverall_relu\n",
      "INFO:tensorflow:loss = 0.0025057013, step = 22865\n",
      "INFO:tensorflow:Saving checkpoints for 23820 into ./saved_models/grid_multi_peakon/1200x15_121_D00_ScaleDataOverall_relu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 23820 into ./saved_models/grid_multi_peakon/1200x15_121_D00_ScaleDataOverall_relu\n",
      "INFO:tensorflow:global_step/sec: 1.58899\n",
      "INFO:tensorflow:loss = 5.895189e-06, step = 23865 (629.332 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24734 into ./saved_models/grid_multi_peakon/1200x15_121_D00_ScaleDataOverall_relu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 24734 into ./saved_models/grid_multi_peakon/1200x15_121_D00_ScaleDataOverall_relu\n",
      "INFO:tensorflow:global_step/sec: 1.52649\n",
      "INFO:tensorflow:loss = 3.3923932e-06, step = 24865 (655.099 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25686 into ./saved_models/grid_multi_peakon/1200x15_121_D00_ScaleDataOverall_relu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 25686 into ./saved_models/grid_multi_peakon/1200x15_121_D00_ScaleDataOverall_relu\n",
      "INFO:tensorflow:global_step/sec: 1.58095\n",
      "INFO:tensorflow:loss = 0.0019664431, step = 25865 (632.532 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 26609 into ./saved_models/grid_multi_peakon/1200x15_121_D00_ScaleDataOverall_relu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 26609 into ./saved_models/grid_multi_peakon/1200x15_121_D00_ScaleDataOverall_relu\n",
      "INFO:tensorflow:global_step/sec: 1.54673\n",
      "INFO:tensorflow:loss = 3.8853364e-06, step = 26865 (646.526 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 27562 into ./saved_models/grid_multi_peakon/1200x15_121_D00_ScaleDataOverall_relu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 27562 into ./saved_models/grid_multi_peakon/1200x15_121_D00_ScaleDataOverall_relu\n",
      "INFO:tensorflow:global_step/sec: 1.59111\n",
      "INFO:tensorflow:loss = 6.4337964e-06, step = 27865 (628.493 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-55868dd1bb02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mtrain_input_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBatchData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_one_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen_one_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     dnn.train(input_fn=train_input_fn(use_tf=True), max_steps=steps, \n\u001b[0;32m---> 40\u001b[0;31m               hooks=[ProcessorSavingHook(preprocessor, model_dir)])\n\u001b[0m",
      "\u001b[0;32m~/miniconda/envs/mltt/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/mltt/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/mltt/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1133\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1134\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/mltt/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1334\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/mltt/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    575\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/mltt/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1051\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1054\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m~/miniconda/envs/mltt/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/mltt/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1199\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1201\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/mltt/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/mltt/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/mltt/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/mltt/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/mltt/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/mltt/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/mltt/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### DNN hyperparameters\n",
    "hidden_units = [1200] * 15\n",
    "# i.e. the number of fine grid points.\n",
    "logits = (fine_grid_fineness.t + 1) * (fine_grid_fineness.x + 1)\n",
    "drop_rate = 0.0\n",
    "drop_type = 'dropout'\n",
    "preprocessor = ScaleDataOverall(momentum=0.999)\n",
    "activation = tf.nn.relu\n",
    "uuid = None\n",
    "\n",
    "### Training hyperparameters #1\n",
    "gradient_clip = 5.0  # May be set to None to turn off gradient clipping\n",
    "\n",
    "### Logging/saving hyperparameters\n",
    "log_steps = 1000  # How many steps to print the current loss.\n",
    "model_dir_base = './saved_models/grid_multi_peakon/'\n",
    "model_dir = model_dir_str(model_dir_base, hidden_units, logits, \n",
    "                          drop_rate=drop_rate, drop_type=drop_type,\n",
    "                          preprocessor=preprocessor, activation=activation, \n",
    "                          uuid=uuid)\n",
    "\n",
    "dnn = create_dnn(hidden_units, logits, drop_rate=drop_rate,\n",
    "                 drop_type=drop_type, model_dir=model_dir, \n",
    "                 log_steps=log_steps, activation=activation, \n",
    "                 gradient_clip=gradient_clip, batch_norm=False)\n",
    "preprocessor.load(model_dir)\n",
    "\n",
    "if TRAIN:\n",
    "    ### Training hyperparameters #2\n",
    "    batch_size = 30\n",
    "    steps = 20000\n",
    "    train_input_fn = preprocessor.data(BatchData(gen_one_data=gen_one_data, batch_size=batch_size))\n",
    "    dnn.train(input_fn=train_input_fn(use_tf=True), max_steps=steps, \n",
    "              hooks=[ProcessorSavingHook(preprocessor, model_dir)])\n",
    "\n",
    "    batch_size = 300\n",
    "    steps = 30000\n",
    "    train_input_fn = preprocessor.data(BatchData(gen_one_data=gen_one_data, batch_size=batch_size))\n",
    "    dnn.train(input_fn=train_input_fn(use_tf=True), max_steps=steps, \n",
    "              hooks=[ProcessorSavingHook(preprocessor, model_dir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './saved_models/grid_multi_peakon/600x10_121_D00_ScaleDataOverall_crelu', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4542c15a58>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:No processor checkpoint file './saved_models/grid_multi_peakon/600x10_121_D00_ScaleDataOverall_crelu/processor-checkpoint' found.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./saved_models/grid_multi_peakon/600x10_121_D00_ScaleDataOverall_crelu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 0 into ./saved_models/grid_multi_peakon/600x10_121_D00_ScaleDataOverall_crelu\n",
      "INFO:tensorflow:loss = 0.07520262, step = 1\n",
      "INFO:tensorflow:global_step/sec: 18.6287\n",
      "INFO:tensorflow:loss = 7.1001045e-06, step = 1001 (53.682 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.5306\n",
      "INFO:tensorflow:loss = 1.8772936e-07, step = 2001 (53.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3875\n",
      "INFO:tensorflow:loss = 5.73213e-08, step = 3001 (54.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.5305\n",
      "INFO:tensorflow:loss = 0.28725165, step = 4001 (53.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.6283\n",
      "INFO:tensorflow:loss = 4.595489e-07, step = 5001 (53.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.6082\n",
      "INFO:tensorflow:loss = 4.512522e-06, step = 6001 (53.740 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.4975\n",
      "INFO:tensorflow:loss = 0.14949366, step = 7001 (54.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.5638\n",
      "INFO:tensorflow:loss = 3.0682764e-07, step = 8001 (53.868 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.5432\n",
      "INFO:tensorflow:loss = 1.7329683e-07, step = 9001 (53.928 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.5742\n",
      "INFO:tensorflow:loss = 2.3114782e-07, step = 10001 (53.838 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.5655\n",
      "INFO:tensorflow:loss = 0.002911508, step = 11001 (53.864 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11125 into ./saved_models/grid_multi_peakon/600x10_121_D00_ScaleDataOverall_crelu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 11125 into ./saved_models/grid_multi_peakon/600x10_121_D00_ScaleDataOverall_crelu\n",
      "INFO:tensorflow:global_step/sec: 18.5529\n",
      "INFO:tensorflow:loss = 4.479275e-06, step = 12001 (53.900 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.6252\n",
      "INFO:tensorflow:loss = 3.8923954e-06, step = 13001 (53.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.6812\n",
      "INFO:tensorflow:loss = 5.9828053e-05, step = 14001 (53.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.6557\n",
      "INFO:tensorflow:loss = 39.452103, step = 15001 (53.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.5935\n",
      "INFO:tensorflow:loss = 2.3299746e-07, step = 16001 (53.782 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.3365\n",
      "INFO:tensorflow:loss = 5.8385296e-05, step = 17001 (54.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.5535\n",
      "INFO:tensorflow:loss = 2.7640299e-05, step = 18001 (53.898 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.8608\n",
      "INFO:tensorflow:loss = 1.3527648e-06, step = 19001 (55.989 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into ./saved_models/grid_multi_peakon/600x10_121_D00_ScaleDataOverall_crelu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 20000 into ./saved_models/grid_multi_peakon/600x10_121_D00_ScaleDataOverall_crelu\n",
      "INFO:tensorflow:Loss for final step: 1.7664969e-07.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./saved_models/grid_multi_peakon/600x10_121_D00_ScaleDataOverall_crelu/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into ./saved_models/grid_multi_peakon/600x10_121_D00_ScaleDataOverall_crelu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 20000 into ./saved_models/grid_multi_peakon/600x10_121_D00_ScaleDataOverall_crelu\n",
      "INFO:tensorflow:loss = 0.025492258, step = 20001\n",
      "INFO:tensorflow:global_step/sec: 4.1276\n",
      "INFO:tensorflow:loss = 2.9480736e-05, step = 21001 (242.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.13207\n",
      "INFO:tensorflow:loss = 7.2689872e-06, step = 22001 (242.010 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22479 into ./saved_models/grid_multi_peakon/600x10_121_D00_ScaleDataOverall_crelu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 22479 into ./saved_models/grid_multi_peakon/600x10_121_D00_ScaleDataOverall_crelu\n",
      "INFO:tensorflow:global_step/sec: 4.14643\n",
      "INFO:tensorflow:loss = 1.1764664e-05, step = 23001 (241.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.1579\n",
      "INFO:tensorflow:loss = 0.00023731476, step = 24001 (240.506 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 24970 into ./saved_models/grid_multi_peakon/600x10_121_D00_ScaleDataOverall_crelu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 24970 into ./saved_models/grid_multi_peakon/600x10_121_D00_ScaleDataOverall_crelu\n",
      "INFO:tensorflow:global_step/sec: 4.13757\n",
      "INFO:tensorflow:loss = 3.7309244e-05, step = 25001 (241.688 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.12082\n",
      "INFO:tensorflow:loss = 4.429409e-05, step = 26001 (242.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.14624\n",
      "INFO:tensorflow:loss = 245.68474, step = 27001 (241.182 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 27467 into ./saved_models/grid_multi_peakon/600x10_121_D00_ScaleDataOverall_crelu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 27467 into ./saved_models/grid_multi_peakon/600x10_121_D00_ScaleDataOverall_crelu\n",
      "INFO:tensorflow:global_step/sec: 4.30206\n",
      "INFO:tensorflow:loss = 0.00018819823, step = 28001 (232.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.32801\n",
      "INFO:tensorflow:loss = 3.592359e-05, step = 29001 (231.053 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into ./saved_models/grid_multi_peakon/600x10_121_D00_ScaleDataOverall_crelu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 30000 into ./saved_models/grid_multi_peakon/600x10_121_D00_ScaleDataOverall_crelu\n",
      "INFO:tensorflow:Loss for final step: 1.4838049e-05.\n"
     ]
    }
   ],
   "source": [
    "### DNN hyperparameters\n",
    "hidden_units = [600] * 10\n",
    "# i.e. the number of fine grid points.\n",
    "logits = (fine_grid_fineness.t + 1) * (fine_grid_fineness.x + 1)\n",
    "drop_rate = 0.0\n",
    "drop_type = 'dropout'\n",
    "preprocessor = ScaleDataOverall(momentum=0.999)\n",
    "activation = tf.nn.crelu\n",
    "uuid = None\n",
    "\n",
    "### Training hyperparameters #1\n",
    "gradient_clip = 5.0  # May be set to None to turn off gradient clipping\n",
    "\n",
    "### Logging/saving hyperparameters\n",
    "log_steps = 1000  # How many steps to print the current loss.\n",
    "model_dir_base = './saved_models/grid_multi_peakon/'\n",
    "model_dir = model_dir_str(model_dir_base, hidden_units, logits, \n",
    "                          drop_rate=drop_rate, drop_type=drop_type,\n",
    "                          preprocessor=preprocessor, activation=activation, \n",
    "                          uuid=uuid)\n",
    "\n",
    "dnn = create_dnn(hidden_units, logits, drop_rate=drop_rate,\n",
    "                 drop_type=drop_type, model_dir=model_dir, \n",
    "                 log_steps=log_steps, activation=activation, \n",
    "                 gradient_clip=gradient_clip, batch_norm=False)\n",
    "preprocessor.load(model_dir)\n",
    "\n",
    "if TRAIN:\n",
    "    ### Training hyperparameters #2\n",
    "    batch_size = 30\n",
    "    steps = 20000\n",
    "    train_input_fn = preprocessor.data(BatchData(gen_one_data=gen_one_data, batch_size=batch_size))\n",
    "    dnn.train(input_fn=train_input_fn(use_tf=True), max_steps=steps, \n",
    "              hooks=[ProcessorSavingHook(preprocessor, model_dir)])\n",
    "\n",
    "    batch_size = 300\n",
    "    steps = 30000\n",
    "    train_input_fn = preprocessor.data(BatchData(gen_one_data=gen_one_data, batch_size=batch_size))\n",
    "    dnn.train(input_fn=train_input_fn(use_tf=True), max_steps=steps, \n",
    "              hooks=[ProcessorSavingHook(preprocessor, model_dir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 1000, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f454231af98>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Processor checkpoint file found, restoring values.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu/model.ckpt-30000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 30000 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu\n",
      "INFO:tensorflow:loss = 2.6279392, step = 30001\n",
      "INFO:tensorflow:global_step/sec: 6.7551\n",
      "INFO:tensorflow:loss = 2.2401578, step = 31001 (148.038 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.72147\n",
      "INFO:tensorflow:loss = 1.7607205, step = 32001 (148.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.72261\n",
      "INFO:tensorflow:loss = 1.2183684, step = 33001 (148.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.78108\n",
      "INFO:tensorflow:loss = 0.9610403, step = 34001 (147.470 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 34046 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 34046 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu\n",
      "INFO:tensorflow:global_step/sec: 6.76478\n",
      "INFO:tensorflow:loss = 0.9609763, step = 35001 (147.824 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.76271\n",
      "INFO:tensorflow:loss = 0.9609763, step = 36001 (147.870 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.80727\n",
      "INFO:tensorflow:loss = 0.9609763, step = 37001 (146.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.7521\n",
      "INFO:tensorflow:loss = 0.9609763, step = 38001 (148.102 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 38108 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 38108 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu\n",
      "INFO:tensorflow:global_step/sec: 6.67038\n",
      "INFO:tensorflow:loss = 0.9609763, step = 39001 (149.917 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 40000 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu\n",
      "INFO:tensorflow:Loss for final step: 0.9609763.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu/model.ckpt-40000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu/model.ckpt.\n",
      "INFO:tensorflow:Saving processor checkpoint for 40000 into ./saved_models/grid_multi_peakon/1200x15_121_D00_NormalisationOverall_selu\n",
      "INFO:tensorflow:loss = 1.0852858, step = 40001\n"
     ]
    }
   ],
   "source": [
    "### DNN hyperparameters\n",
    "hidden_units = [1200] * 15\n",
    "# i.e. the number of fine grid points.\n",
    "logits = (fine_grid_fineness.t + 1) * (fine_grid_fineness.x + 1)\n",
    "drop_rate = 0.0\n",
    "drop_type = 'dropout'\n",
    "preprocessor = NormalisationOverall(momentum=0.999)\n",
    "activation = tf.nn.selu\n",
    "uuid = None\n",
    "\n",
    "### Training hyperparameters #1\n",
    "gradient_clip = 1.0  # May be set to None to turn off gradient clipping\n",
    "\n",
    "### Logging/saving hyperparameters\n",
    "log_steps = 1000  # How many steps to print the current loss.\n",
    "model_dir_base = './saved_models/grid_multi_peakon/'\n",
    "model_dir = model_dir_str(model_dir_base, hidden_units, logits, \n",
    "                          drop_rate=drop_rate, drop_type=drop_type,\n",
    "                          preprocessor=preprocessor, activation=activation, \n",
    "                          uuid=uuid)\n",
    "\n",
    "dnn = create_dnn(hidden_units, logits, drop_rate=drop_rate,\n",
    "                 drop_type=drop_type, model_dir=model_dir, \n",
    "                 log_steps=log_steps, activation=activation, \n",
    "                 gradient_clip=gradient_clip, batch_norm=False)\n",
    "preprocessor.load(model_dir)\n",
    "\n",
    "if TRAIN:\n",
    "    ### Training hyperparameters #2\n",
    "    batch_size = 30\n",
    "    steps = 40000\n",
    "    train_input_fn = preprocessor.data(BatchData(gen_one_data=gen_one_data, batch_size=batch_size))\n",
    "    dnn.train(input_fn=train_input_fn(use_tf=True), max_steps=steps, \n",
    "              hooks=[ProcessorSavingHook(preprocessor, model_dir)])\n",
    "\n",
    "    batch_size = 300\n",
    "    steps = 50000\n",
    "    train_input_fn = preprocessor.data(BatchData(gen_one_data=gen_one_data, batch_size=batch_size))\n",
    "    dnn.train(input_fn=train_input_fn(use_tf=True), max_steps=steps, \n",
    "              hooks=[ProcessorSavingHook(preprocessor, model_dir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DNN hyperparameters\n",
    "hidden_units = [600] * 15\n",
    "# i.e. the number of fine grid points.\n",
    "logits = (fine_grid_fineness.t + 1) * (fine_grid_fineness.x + 1)\n",
    "drop_rate = 0.0\n",
    "drop_type = 'dropout'\n",
    "preprocessor = ScaleDataOverall(momentum=0.999)\n",
    "activation = tf.nn.crelu\n",
    "uuid = None\n",
    "\n",
    "### Training hyperparameters #1\n",
    "gradient_clip = 5.0  # May be set to None to turn off gradient clipping\n",
    "\n",
    "### Logging/saving hyperparameters\n",
    "log_steps = 1000  # How many steps to print the current loss.\n",
    "model_dir_base = './saved_models/grid_multi_peakon/'\n",
    "model_dir = model_dir_str(model_dir_base, hidden_units, logits, \n",
    "                          drop_rate=drop_rate, drop_type=drop_type,\n",
    "                          preprocessor=preprocessor, activation=activation, \n",
    "                          uuid=uuid)\n",
    "\n",
    "dnn = create_dnn(hidden_units, logits, drop_rate=drop_rate,\n",
    "                 drop_type=drop_type, model_dir=model_dir, \n",
    "                 log_steps=log_steps, activation=activation, \n",
    "                 gradient_clip=gradient_clip, batch_norm=False)\n",
    "preprocessor.load(model_dir)\n",
    "\n",
    "if TRAIN:\n",
    "    ### Training hyperparameters #2\n",
    "    batch_size = 30\n",
    "    steps = 20000\n",
    "    train_input_fn = preprocessor.data(BatchData(gen_one_data=gen_one_data, batch_size=batch_size))\n",
    "    dnn.train(input_fn=train_input_fn(use_tf=True), max_steps=steps, \n",
    "              hooks=[ProcessorSavingHook(preprocessor, model_dir)])\n",
    "\n",
    "    batch_size = 300\n",
    "    steps = 30000\n",
    "    train_input_fn = preprocessor.data(BatchData(gen_one_data=gen_one_data, batch_size=batch_size))\n",
    "    dnn.train(input_fn=train_input_fn(use_tf=True), max_steps=steps, \n",
    "              hooks=[ProcessorSavingHook(preprocessor, model_dir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DNN hyperparameters\n",
    "hidden_units = [600] * 5\n",
    "# i.e. the number of fine grid points.\n",
    "logits = (fine_grid_fineness.t + 1) * (fine_grid_fineness.x + 1)\n",
    "drop_rate = 0.0\n",
    "drop_type = 'dropout'\n",
    "preprocessor = ScaleDataOverall(momentum=0.999)\n",
    "activation = tf.nn.crelu\n",
    "uuid = None\n",
    "\n",
    "### Training hyperparameters #1\n",
    "gradient_clip = 5.0  # May be set to None to turn off gradient clipping\n",
    "\n",
    "### Logging/saving hyperparameters\n",
    "log_steps = 1000  # How many steps to print the current loss.\n",
    "model_dir_base = './saved_models/grid_multi_peakon/'\n",
    "model_dir = model_dir_str(model_dir_base, hidden_units, logits, \n",
    "                          drop_rate=drop_rate, drop_type=drop_type,\n",
    "                          preprocessor=preprocessor, activation=activation, \n",
    "                          uuid=uuid)\n",
    "\n",
    "dnn = create_dnn(hidden_units, logits, drop_rate=drop_rate,\n",
    "                 drop_type=drop_type, model_dir=model_dir, \n",
    "                 log_steps=log_steps, activation=activation, \n",
    "                 gradient_clip=gradient_clip, batch_norm=False)\n",
    "preprocessor.load(model_dir)\n",
    "\n",
    "if TRAIN:\n",
    "    ### Training hyperparameters #2\n",
    "    batch_size = 30\n",
    "    steps = 6000\n",
    "    train_input_fn = preprocessor.data(BatchData(gen_one_data=gen_one_data, batch_size=batch_size))\n",
    "    dnn.train(input_fn=train_input_fn(use_tf=True), max_steps=steps, \n",
    "              hooks=[ProcessorSavingHook(preprocessor, model_dir)])\n",
    "\n",
    "    batch_size = 300\n",
    "    steps = 10000\n",
    "    train_input_fn = preprocessor.data(BatchData(gen_one_data=gen_one_data, batch_size=batch_size))\n",
    "    dnn.train(input_fn=train_input_fn(use_tf=True), max_steps=steps, \n",
    "              hooks=[ProcessorSavingHook(preprocessor, model_dir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DNN hyperparameters\n",
    "hidden_units = [1200] * 10\n",
    "# i.e. the number of fine grid points.\n",
    "logits = (fine_grid_fineness.t + 1) * (fine_grid_fineness.x + 1)\n",
    "drop_rate = 0.0\n",
    "drop_type = 'dropout'\n",
    "preprocessor = NormalisationOverall(momentum=0.999)\n",
    "activation = tf.nn.elu\n",
    "uuid = None\n",
    "\n",
    "### Training hyperparameters #1\n",
    "gradient_clip = 1.0  # May be set to None to turn off gradient clipping\n",
    "\n",
    "### Logging/saving hyperparameters\n",
    "log_steps = 1000  # How many steps to print the current loss.\n",
    "model_dir_base = './saved_models/grid_multi_peakon/'\n",
    "model_dir = model_dir_str(model_dir_base, hidden_units, logits, \n",
    "                          drop_rate=drop_rate, drop_type=drop_type,\n",
    "                          preprocessor=preprocessor, activation=activation, \n",
    "                          uuid=uuid)\n",
    "\n",
    "dnn = create_dnn(hidden_units, logits, drop_rate=drop_rate,\n",
    "                 drop_type=drop_type, model_dir=model_dir, \n",
    "                 log_steps=log_steps, activation=activation, \n",
    "                 gradient_clip=gradient_clip, batch_norm=False)\n",
    "preprocessor.load(model_dir)\n",
    "\n",
    "if TRAIN:\n",
    "    ### Training hyperparameters #2\n",
    "    batch_size = 30\n",
    "    steps = 20000\n",
    "    train_input_fn = preprocessor.data(BatchData(gen_one_data=gen_one_data, batch_size=batch_size))\n",
    "    dnn.train(input_fn=train_input_fn(use_tf=True), max_steps=steps, \n",
    "              hooks=[ProcessorSavingHook(preprocessor, model_dir)])\n",
    "\n",
    "    batch_size = 300\n",
    "    steps = 30000\n",
    "    train_input_fn = preprocessor.data(BatchData(gen_one_data=gen_one_data, batch_size=batch_size))\n",
    "    dnn.train(input_fn=train_input_fn(use_tf=True), max_steps=steps, \n",
    "              hooks=[ProcessorSavingHook(preprocessor, model_dir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DNN hyperparameters\n",
    "hidden_units = [600] * 10\n",
    "# i.e. the number of fine grid points.\n",
    "logits = (fine_grid_fineness.t + 1) * (fine_grid_fineness.x + 1)\n",
    "drop_rate = 0.0\n",
    "drop_type = 'dropout'\n",
    "preprocessor = ScaleDataOverall(momentum=0.999)\n",
    "activation = tf.nn.selu\n",
    "uuid = None\n",
    "\n",
    "### Training hyperparameters #1\n",
    "gradient_clip = 1.0  # May be set to None to turn off gradient clipping\n",
    "\n",
    "### Logging/saving hyperparameters\n",
    "log_steps = 1000  # How many steps to print the current loss.\n",
    "model_dir_base = './saved_models/grid_multi_peakon/'\n",
    "model_dir = model_dir_str(model_dir_base, hidden_units, logits, \n",
    "                          drop_rate=drop_rate, drop_type=drop_type,\n",
    "                          preprocessor=preprocessor, activation=activation, \n",
    "                          uuid=uuid)\n",
    "\n",
    "dnn = create_dnn(hidden_units, logits, drop_rate=drop_rate,\n",
    "                 drop_type=drop_type, model_dir=model_dir, \n",
    "                 log_steps=log_steps, activation=activation, \n",
    "                 gradient_clip=gradient_clip, batch_norm=False)\n",
    "preprocessor.load(model_dir)\n",
    "\n",
    "if TRAIN:\n",
    "    ### Training hyperparameters #2\n",
    "    batch_size = 30\n",
    "    steps = 20000\n",
    "    train_input_fn = preprocessor.data(BatchData(gen_one_data=gen_one_data, batch_size=batch_size))\n",
    "    dnn.train(input_fn=train_input_fn(use_tf=True), max_steps=steps, \n",
    "              hooks=[ProcessorSavingHook(preprocessor, model_dir)])\n",
    "\n",
    "    batch_size = 300\n",
    "    steps = 30000\n",
    "    train_input_fn = preprocessor.data(BatchData(gen_one_data=gen_one_data, batch_size=batch_size))\n",
    "    dnn.train(input_fn=train_input_fn(use_tf=True), max_steps=steps, \n",
    "              hooks=[ProcessorSavingHook(preprocessor, model_dir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
